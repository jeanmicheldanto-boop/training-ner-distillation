# üöÄ Guide d'Utilisation - Workflow NER Distillation RunPod

Ce guide explique comment utiliser les scripts pour orchestrer et suivre votre workflow d'annotation et de training sur RunPod.

---

## üìÅ Fichiers cr√©√©s

1. **`monitor_jobs.py`** - Monitoring en temps r√©el d'un job sp√©cifique
2. **`workflow.py`** - Orchestration compl√®te du workflow (annotation ‚Üí training)
3. **`test_endpoint.py`** - Tests manuels de l'endpoint (d√©j√† existant, corrig√©)
4. **`CORPUS_UPLOAD.md`** - Guide d√©taill√© pour uploader le corpus

---

## ‚öôÔ∏è Configuration initiale (√† faire UNE FOIS par session PowerShell)

```powershell
# D√©finir les variables d'environnement
$env:RUNPOD_ENDPOINT_ID = "wupg1xsork5mk7"
$env:RUNPOD_API_KEY = "VOTRE_CLE_API_ICI"
```

**üí° Astuce:** Pour rendre ces variables persistantes entre sessions, ajoutez-les √† votre profil PowerShell:
```powershell
notepad $PROFILE
# Ajoutez les deux lignes ci-dessus et sauvegardez
```

---

## üéØ Sc√©narios d'utilisation

### üìã Sc√©nario 1: Workflow complet automatis√© (RECOMMAND√â)

**Utilisation:** Lancer annotation puis training automatiquement, avec suivi en temps r√©el.

```powershell
# 1. Uploadez d'abord le corpus (voir CORPUS_UPLOAD.md)
# 2. Lancez le workflow complet
python workflow.py --corpus-path /runpod-volume/corpus_fr_100k_medico_FINAL.txt
```

**Ce script va:**
- ‚úÖ Soumettre le job d'annotation
- ‚è≥ Attendre la fin de l'annotation (avec progress updates toutes les minutes)
- ‚úÖ Soumettre le job de training automatiquement
- ‚è≥ Attendre la fin du training
- üìä Afficher les r√©sultats et la dur√©e totale

**Options avanc√©es:**
```powershell
# Training seul (si annotation d√©j√† faite)
python workflow.py --corpus-path /runpod-volume/corpus.txt --skip-annotation

# Avec timeouts personnalis√©s (en secondes)
python workflow.py --corpus-path /runpod-volume/corpus.txt --annotation-timeout 3600 --training-timeout 7200

# Aide compl√®te
python workflow.py --help
```

---

### üîç Sc√©nario 2: Monitoring d'un job sp√©cifique

**Utilisation:** Suivre un job d√©j√† lanc√© (depuis test_endpoint.py ou la console).

```powershell
# Suivre un job avec son ID
python monitor_jobs.py "fdb73da3-d662-42ec-98e1-bc4eaf5529e3-e2"

# Avec timeout personnalis√© (2 heures)
python monitor_jobs.py "job-id-ici" --timeout 7200
```

**Ce script va:**
- üîÑ Interroger le statut du job toutes les 5 secondes
- üìä Afficher les changements de statut (IN_QUEUE ‚Üí IN_PROGRESS ‚Üí COMPLETED)
- ‚è±Ô∏è Afficher la dur√©e √©coul√©e et le temps d'ex√©cution
- ‚úÖ Afficher l'output final si le job r√©ussit
- ‚ùå Afficher les erreurs si le job √©choue

---

### üß™ Sc√©nario 3: Test manuel de l'endpoint

**Utilisation:** Tester rapidement l'endpoint sans orchestration.

```powershell
# Lance 2 jobs de test (annotation + training) et affiche les IDs
python test_endpoint.py
```

**Ce script va:**
- üì§ Soumettre un job d'annotation de test
- üì§ Soumettre un job de training de test
- üìä Afficher les job IDs pour monitoring manuel
- ‚è≥ V√©rifier le statut initial (apr√®s 3 secondes)

**Ensuite, suivez un job avec monitor_jobs.py:**
```powershell
python monitor_jobs.py "job-id-affich√©-par-test"
```

---

## üß™ Workflow de test recommand√© (AVANT le gros corpus)

**Objectif:** Valider que tout fonctionne avant de lancer un job long et co√ªteux.

### √âtape 1: Cr√©er un mini-corpus de test

```powershell
# Cr√©er un fichier de 100 lignes pour test rapide
Get-Content C:\Users\Lenovo\dataner\corpus\corpus_fr_100k_medico_FINAL.txt -TotalCount 100 | Out-File C:\Users\Lenovo\dataner\corpus\corpus_test_100.txt -Encoding UTF8
```

### √âtape 2: Uploader le mini-corpus sur RunPod

Suivez les instructions dans `CORPUS_UPLOAD.md` pour uploader `corpus_test_100.txt` vers `/runpod-volume/corpus_test_100.txt`

### √âtape 3: Lancer le test workflow

```powershell
python workflow.py --corpus-path /runpod-volume/corpus_test_100.txt
```

**Dur√©e attendue:** 2-5 minutes (annotation rapide + training court)

**Si √ßa marche ‚úÖ:**
- Votre handler est fonctionnel
- Les imports et configs sont corrects
- Vous pouvez passer au gros corpus

**Si √ßa √©choue ‚ùå:**
- Lisez les logs d'erreur affich√©s
- V√©rifiez les Runtime Logs dans la console RunPod
- Corrigez le probl√®me avant de passer au gros corpus

### √âtape 4: Lancer le workflow complet

```powershell
# Uploadez le gros corpus (voir CORPUS_UPLOAD.md)
# Puis lancez:
python workflow.py --corpus-path /runpod-volume/corpus_fr_100k_medico_FINAL.txt
```

**Dur√©e attendue:** 1-3 heures (annotation ~30-60 min, training ~1-2h)

---

## üìä Interpr√©ter les statuts des jobs

### Statuts RunPod:

| Statut | Signification | Action |
|--------|---------------|--------|
| `IN_QUEUE` | Job en attente d'un worker disponible | Attendre (normal si pas de worker actif) |
| `IN_PROGRESS` | Job en cours d'ex√©cution | Attendre, surveiller les logs |
| `COMPLETED` | Job termin√© avec succ√®s | ‚úÖ R√©cup√©rer les outputs/artefacts |
| `FAILED` | Job √©chou√© | ‚ùå Lire les logs d'erreur, corriger et relancer |
| `CANCELLED` | Job annul√© manuellement | V√©rifier pourquoi, relancer si n√©cessaire |

### Logs disponibles:

- **Console RunPod:** https://console.runpod.io/jobs?id=<job_id>
- **Output dans monitor_jobs.py:** Affiche le champ `output` du r√©sultat JSON
- **Runtime logs:** Accessible dans la console RunPod (onglet Logs du job)

---

## üÜò R√©solution de probl√®mes

### ‚ùå "Not Found" (404)
**Cause:** Mauvais endpoint ID ou endpoint non Ready  
**Solution:** V√©rifiez l'endpoint ID dans la console RunPod, attendez que l'√©tat soit "Ready"

### ‚ùå "Unauthorized" (401/403)
**Cause:** API key invalide ou permissions insuffisantes  
**Solution:** V√©rifiez que `$env:RUNPOD_API_KEY` est correcte et a les permissions "All" ou "Invoke"

### ‚ùå Job reste en "IN_QUEUE" ind√©finiment
**Cause:** Aucun worker disponible (endpoint Serverless idle)  
**Solution:** Attendez qu'un worker d√©marre (cold start ~30-60s) ou augmentez le nombre de workers dans les settings de l'endpoint

### ‚ùå Job √©choue avec "FileNotFoundError"
**Cause:** Corpus non upload√© ou chemin incorrect  
**Solution:** 
1. V√©rifiez que le corpus est bien upload√© sur le volume
2. Utilisez un pod temporaire pour lister les fichiers:
   ```bash
   ls -la /runpod-volume/
   ```
3. Corrigez le chemin dans la commande `workflow.py`

### ‚ùå Job √©choue avec "ImportError" ou "ModuleNotFoundError"
**Cause:** D√©pendances manquantes dans l'image Docker  
**Solution:**
1. V√©rifiez le `requirements.txt` dans le repo
2. Ajoutez les d√©pendances manquantes
3. Rebuild l'endpoint (push vers GitHub d√©clenche un rebuild automatique)

### ‚è±Ô∏è Timeout atteint
**Cause:** Job prend plus de temps que le timeout configur√©  
**Solution:**
- Augmentez le timeout:
  ```powershell
  python workflow.py --corpus-path /path --annotation-timeout 10800 --training-timeout 21600
  # (3h et 6h respectivement)
  ```
- Ou suivez le job dans la console RunPod (il continue m√™me apr√®s timeout du script)

---

## üéØ Prochaines √©tapes apr√®s succ√®s

### 1. T√©l√©charger les artefacts

Les mod√®les entra√Æn√©s sont stock√©s dans `/app/artifacts` sur le volume RunPod.

**Via un pod temporaire:**
```bash
# D√©marrez un pod avec le volume attach√©
cd /app/artifacts
ls -lh
# T√©l√©chargez via l'interface web ou SCP
```

**Via runpodctl:**
```powershell
.\runpodctl.exe receive data <VOLUME_ID>:/app/artifacts C:\Users\Lenovo\dataner\artifacts
```

### 2. √âvaluer le mod√®le distill√©

Comparez les performances teacher vs student sur un jeu de test:
- F1-score par entit√© (PER, LOC, ORG, MISC)
- Taille du mod√®le (MB)
- Vitesse d'inf√©rence (tokens/sec)

### 3. Optimiser (si n√©cessaire)

Si les performances du student sont insuffisantes:
- Ajustez les hyperparam√®tres dans `kd_camembert.yaml`
- Augmentez le nombre d'√©poques
- Modifiez les pond√©rations des pertes (Œ±, Œ≤, Œ≥, Œ¥)
- Relancez le training avec `--skip-annotation`

---

## üìö R√©f√©rence rapide des commandes

```powershell
# Configuration (une fois par session)
$env:RUNPOD_ENDPOINT_ID = "wupg1xsork5mk7"
$env:RUNPOD_API_KEY = "votre_cl√©"

# Workflow complet (annotation + training)
python workflow.py --corpus-path /runpod-volume/corpus_fr_100k_medico_FINAL.txt

# Training seul
python workflow.py --corpus-path /runpod-volume/corpus.txt --skip-annotation

# Monitoring d'un job
python monitor_jobs.py "job-id-ici"

# Test rapide de l'endpoint
python test_endpoint.py

# Cr√©er un mini-corpus de test
Get-Content corpus\corpus_fr_100k_medico_FINAL.txt -TotalCount 100 | Out-File corpus\corpus_test_100.txt -Encoding UTF8
```

---

## üí° Conseils d'optimisation

### Co√ªts:
- **Testez d'abord avec un petit corpus** pour valider le workflow
- **Utilisez GPU 3090** pour le training (bon ratio performance/prix)
- **Arr√™tez les pods temporaires** d√®s que l'upload est termin√©
- **Surveillez les workers actifs** dans l'endpoint Serverless (facturation √† l'utilisation)

### Performance:
- **Compression:** Compressez le corpus avant upload si tr√®s volumineux
- **Batch size:** Ajustez dans `kd_camembert.yaml` selon la VRAM disponible
- **Workers:** Augmentez le nombre de workers si vous avez plusieurs jobs en parall√®le

### S√©curit√©:
- **Ne commitez jamais** l'API key dans git
- **Utilisez des cl√©s s√©par√©es** pour dev/prod
- **R√©vocation:** R√©vocez les cl√©s apr√®s usage ou en cas de fuite

---

**Besoin d'aide?** Consultez `CORPUS_UPLOAD.md` pour l'upload du corpus, ou les logs dans la console RunPod pour d√©bugger les erreurs runtime.
