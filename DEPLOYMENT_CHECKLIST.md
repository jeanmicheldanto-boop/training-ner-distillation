# Pre-Deployment Checklist

## ‚úÖ Local Environment Setup

### Code Repository
- [ ] Git repo initialized locally (`git init` ‚úì)
- [ ] All 23 pipeline files created and committed
- [ ] `.gitignore` configured (excludes data, artifacts, binaries)
- [ ] 4 commits in git history:
  - [ ] Commit 1: Initial NER distillation pipeline (5e647d9)
  - [ ] Commit 2: RunPod deployment guide (ecb7ca9)
  - [ ] Commit 3: Setup + README (46f3d13)
  - [ ] Commit 4: Metrics + validation (dcd7093)

### Documentation
- [ ] `README.md` - Complete project overview ‚úÖ
- [ ] `PROJECT_SUMMARY.md` - Technical strategy details ‚úÖ
- [ ] `RUNPOD_GUIDE.md` - 5-phase deployment guide ‚úÖ
- [ ] `METRICS.md` - Performance tracking guide ‚úÖ
- [ ] `setup_runpod.sh` - Automated setup script ‚úÖ

### Core Pipeline Files (23 total)
- [ ] `training_ner/models.py` - Teacher + Student architecture
- [ ] `training_ner/losses.py` - 4-way distillation loss
- [ ] `training_ner/pruning.py` - Attention head pruning
- [ ] `training_ner/data_loader.py` - NER dataset + tokenization
- [ ] `training_ner/utils.py` - Logging, checkpointing, monitoring
- [ ] `training_ner/train_kd.py` - Main training loop
- [ ] `training_ner/prune_heads.py` - Pruning orchestration
- [ ] `training_ner/finetune_postprune.py` - Post-pruning fine-tuning
- [ ] `training_ner/inference.py` - NER extraction
- [ ] `training_ner/annotate_corpus.py` - Auto-annotation via teacher
- [ ] `training_ner/validate_setup.py` - Pre-deployment validation
- [ ] `training_ner/requirements.txt` - Python dependencies
- [ ] `configs/kd_camembert.yaml` - Complete configuration
- [ ] `data/label2id.json` - Label encoding (7 labels)
- [ ] Placeholder `.jsonl` files for train/val/test data

### Data Preparation
- [ ] Corpus file ready: `corpus_fr_100k_medico_FINAL.txt` (11.47 MB)
  - [ ] 96,230 phrases total
  - [ ] 46.5% medical/admin (24,683 phrases)
  - [ ] 28.3% narrative (14,768 phrases)
  - [ ] 25.2% Wikipedia (13,380 phrases)

---

## ‚úÖ GitHub Setup

### GitHub Repository Creation
- [ ] Create new public repo on GitHub.com
  - [ ] Name: `ner-distillation`
  - [ ] Description: "Knowledge Distillation + Pruning for French CamemBERT-NER"
  - [ ] Visibility: Public
  - [ ] Initialize: Empty (no README, no .gitignore - we have local versions)

### Personal Access Token (PAT)
- [ ] Generate PAT on GitHub:
  - [ ] Settings ‚Üí Developer settings ‚Üí Personal access tokens ‚Üí Tokens (classic)
  - [ ] Scopes: `repo` (full control of private repositories), `workflow`
  - [ ] Copy token somewhere safe (won't be shown again)
  - [ ] **Token format**: `ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`

### Push to GitHub
- [ ] Add remote: `git remote add origin https://github.com/YOUR_USERNAME/ner-distillation.git`
- [ ] Push commits: `git branch -M main; git push -u origin main`
  - Use PAT as password when prompted
  - Or use SSH key if pre-configured
- [ ] Verify on GitHub.com: All 4 commits visible, all files present

---

## ‚úÖ RunPod Setup

### RunPod Account & Billing
- [ ] RunPod account created (https://www.runpod.io)
- [ ] Payment method added (credit card linked)
- [ ] Account activated (can create pods)
- [ ] Estimated budget: $10-25 for full training
  - [ ] RTX 4090: $0.70/hour √ó 15h = ~$10.50
  - [ ] A100: $1.50/hour √ó 15h = ~$22.50
  - [ ] 50GB volume: +$0.10/h = negligible

### RunPod Pod Creation
- [ ] **Pod Template**: PyTorch 2.0+ CUDA 11.8
  - [ ] Base container: `runpod/pytorch:2.0.1-py3.10-cuda11.8.0-devel`
  - [ ] Verified CUDA version compatible with Torch 2.0
  
- [ ] **GPU Selection**:
  - [ ] GPU: RTX 4090 or A100 (minimum 24GB VRAM)
  - [ ] CPU: ‚â• 8 vCPUs
  - [ ] RAM: ‚â• 32GB
  
- [ ] **Storage**:
  - [ ] Persistent volume: 50GB (minimum)
  - [ ] Should contain: code, corpus, models, checkpoints
  
- [ ] **Start Pod**: Note down:
  - [ ] Pod ID: `pod_xxxxxxxxxx`
  - [ ] Public IP: `xxx.xxx.xxx.xxx`
  - [ ] SSH Port: Usually 22 (check pod details)
  - [ ] Root password: Generated by RunPod

### SSH Connection to Pod
- [ ] SSH connection verified:
  ```bash
  ssh root@<POD_IP> -p 22
  ```
- [ ] First login successful
- [ ] Can run `nvidia-smi` to verify GPU
- [ ] Can run `python --version` to verify Python 3.10+

---

## ‚úÖ Data Upload to RunPod

### Git Clone on Pod
- [ ] SSH into pod: `ssh root@<POD_IP>`
- [ ] Create workspace: `mkdir -p /workspace && cd /workspace`
- [ ] Clone repo: `git clone https://github.com/YOUR_USERNAME/ner-distillation.git`
- [ ] Navigate: `cd /workspace/ner-distillation`

### Corpus Upload
- [ ] SCP corpus file to pod:
  ```bash
  scp -P 22 corpus_fr_100k_medico_FINAL.txt root@<POD_IP>:/workspace/ner-distillation/data/
  ```
- [ ] Verify file on pod: `ls -lh /workspace/ner-distillation/data/corpus_fr_100k_medico_FINAL.txt`
  - [ ] File size: ~11.47 MB
  - [ ] File readable: `head -n 10 /workspace/ner-distillation/data/corpus_fr_100k_medico_FINAL.txt`

---

## ‚úÖ RunPod Automated Setup

### Environment Preparation
- [ ] On pod, run setup script:
  ```bash
  cd /workspace/ner-distillation
  bash setup_runpod.sh
  ```
- [ ] Verify output:
  - [ ] ‚úÖ CUDA available
  - [ ] ‚úÖ GPU detected
  - [ ] ‚úÖ All packages installed
  - [ ] ‚úÖ Setup complete

### Pre-Training Validation
- [ ] On pod, run validation:
  ```bash
  python quick_validation.py
  ```
- [ ] Verify all checks pass:
  - [ ] ‚úÖ Python 3.10+
  - [ ] ‚úÖ PyTorch 2.0+
  - [ ] ‚úÖ CUDA available
  - [ ] ‚úÖ All packages installed
  - [ ] ‚úÖ Teacher model accessible
  - [ ] ‚úÖ Config valid
  - [ ] ‚úÖ Sufficient GPU memory (>20GB)
  - [ ] ‚úÖ Sufficient disk space (>100GB)

---

## ‚úÖ Training Pipeline Execution

### Phase 1: Auto-Annotation (2-4 hours)
- [ ] On pod:
  ```bash
  python training_ner/annotate_corpus.py \
    --input data/corpus_fr_100k_medico_FINAL.txt \
    --output training_ner/data/ \
    --teacher_model Jean-Baptiste/camembert-ner \
    --batch_size 32
  ```
- [ ] Expected output:
  - [ ] `training_ner/data/train.jsonl` (~77k examples, 80%)
  - [ ] `training_ner/data/val.jsonl` (~10k examples, 10%)
  - [ ] `training_ner/data/test.jsonl` (~9k examples, 10%)
  - [ ] Log file with annotation progress

### Phase 2: Knowledge Distillation (4-8 hours)
- [ ] On pod:
  ```bash
  python training_ner/train_kd.py \
    --config configs/kd_camembert.yaml \
    --output artifacts/student_10L \
    --epochs 10 \
    --batch_size 16
  ```
- [ ] Monitor training:
  - [ ] Checkpoints saved every epoch
  - [ ] Best model selected based on val F1
  - [ ] Logs show loss decreasing
  - [ ] Final student F1 ~0.90 (¬±0.02)
- [ ] Expected artifacts:
  - [ ] `artifacts/student_10L/best_model/`
  - [ ] `artifacts/student_10L/metrics.json`
  - [ ] `artifacts/student_10L/training.log`

### Phase 3: Head Pruning (30-60 minutes)
- [ ] On pod:
  ```bash
  python training_ner/prune_heads.py \
    --model artifacts/student_10L/best_model \
    --pruning_ratio 0.25 \
    --output artifacts/student_10L_pruned
  ```
- [ ] Verify pruning:
  - [ ] 25% attention heads removed
  - [ ] Pruning mask saved for reproducibility
  - [ ] Model size reduced (~45%)

### Phase 4: Post-Pruning Fine-tuning (1-2 hours)
- [ ] On pod:
  ```bash
  python training_ner/finetune_postprune.py \
    --model artifacts/student_10L_pruned/model \
    --config configs/kd_camembert.yaml \
    --output artifacts/student_10L_final \
    --epochs 2
  ```
- [ ] Verify recovery:
  - [ ] F1 recovers after pruning
  - [ ] Final F1 ~0.90 (recovered from -0.01 to -0.02 drop)

### Phase 5: Testing & Metrics (30-45 minutes)
- [ ] On pod:
  ```bash
  python training_ner/inference.py \
    --model artifacts/student_10L_final \
    --input training_ner/data/test.jsonl \
    --output results/predictions.jsonl
  ```
- [ ] Extract metrics:
  ```bash
  python -c "
  import json
  with open('results/predictions.jsonl') as f:
    predictions = [json.loads(line) for line in f]
  print(f'F1 Score: {sum(p[\"f1\"] for p in predictions) / len(predictions):.4f}')
  print(f'Inference time: {sum(p[\"inference_time\"] for p in predictions) / len(predictions):.2f}ms')
  "
  ```

---

## ‚úÖ Final Validation

### Model Download
- [ ] Download final model from pod to local:
  ```bash
  scp -P 22 -r root@<POD_IP>:/workspace/ner-distillation/artifacts/student_10L_final ~/Downloads/
  ```

### End-to-End Pipeline Test
- [ ] Load final model in production 3-engine pipeline
- [ ] Test on held-out medical/social documents
- [ ] Measure F1 score drop:
  - [ ] F1 drop ‚â§ -1.0: **‚úÖ GO** (accept model)
  - [ ] F1 drop > -1.0: **‚ùå NO-GO** (reject model, try different approach)

### Performance Metrics Validation
- [ ] Expected metrics achieved:
  - [ ] Inference latency: 90-100ms per document (was 150ms teacher)
  - [ ] Model size: ~240MB (was 440MB teacher)
  - [ ] F1 score: ~0.90 (was 0.92 teacher)
  - [ ] Speedup: 40-50%
  - [ ] Compression: 45%

---

## ‚úÖ Deployment (if GO)

### Production Deployment
- [ ] Final model saved locally: `~/Downloads/student_10L_final/`
- [ ] Model tested in production pipeline
- [ ] Performance metrics logged
- [ ] Deploy to production system
- [ ] Monitor performance in production

### Cleanup
- [ ] Delete RunPod pod (stops billing)
  - [ ] Pod deletion: On RunPod dashboard, click "Terminate"
  - [ ] Confirm deletion
- [ ] Delete persistent volume (optional, for next training)
- [ ] Keep GitHub repo for future reference

---

## üî¥ Troubleshooting During Execution

### If CUDA OOM during training:
- [ ] Reduce batch_size: `--batch_size 8` (from 16)
- [ ] Reduce max_seq_length: `max_seq_length: 256` (from 512)
- [ ] Increase gradient_accumulation_steps: `4` (from 1)

### If F1 drops too much after pruning:
- [ ] Reduce pruning_ratio: `--pruning_ratio 0.15` (from 0.25)
- [ ] Increase fine-tuning epochs: `--epochs 4` (from 2)
- [ ] Lower learning_rate: `1e-5` (from 2e-5)

### If teacher model not found:
- [ ] Check internet connection on pod
- [ ] Manually download: `python -c "from transformers import AutoTokenizer; AutoTokenizer.from_pretrained('Jean-Baptiste/camembert-ner')"`

### If validation F1 very low (<0.70):
- [ ] Check data format: `cat training_ner/data/label2id.json`
- [ ] Verify label alignment: `python quick_validation.py`
- [ ] Check corpus preprocessing (tokenization)

---

## üìä Success Criteria

‚úÖ **PASS** if ALL of the following:
- [ ] Git repo created on GitHub with 4 commits
- [ ] RunPod pod runs without errors
- [ ] Auto-annotation completes successfully (train/val/test splits created)
- [ ] Knowledge distillation training completes 10 epochs
- [ ] Student F1 ‚â• 0.88 (within -0.04 of teacher 0.92)
- [ ] Head pruning reduces model size by 45%
- [ ] Post-pruning fine-tuning recovers F1 to ~0.90
- [ ] End-to-end pipeline F1 drop ‚â§ -1.0
- [ ] Inference latency < 100ms per document
- [ ] Model successfully downloaded and tested locally

---

## üìã Cleanup Checklist

After successful deployment:
- [ ] Delete RunPod pod to stop billing
- [ ] Backup final model locally
- [ ] Document actual F1 drop achieved
- [ ] Update METRICS.md with actual results
- [ ] Commit results to GitHub
- [ ] Archive artifacts folder locally

---

**Document Status**: Ready for deployment
**Last Updated**: 2024-01-XX
**Next Action**: Create GitHub repo (Phase 1 of RUNPOD_GUIDE.md)

