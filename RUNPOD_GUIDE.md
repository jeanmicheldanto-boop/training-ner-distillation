# ğŸš€ Guide complet : De local Ã  RunPod

## Phase 1 : CrÃ©er un repo GitHub (5 minutes)

### Ã‰tape 1 : CrÃ©er le repo sur GitHub

1. Allez sur **https://github.com/new**
2. Remplissez :
   - **Repository name** : `ner-distillation` (ou ce que vous voulez)
   - **Description** : "NER distillation pipeline - Knowledge Distillation + Pruning for CamemBERT"
   - **Visibility** : Public (sinon RunPod ne pourra pas cloner sans token)
   - **Cocher** : "Add a README file"
3. Cliquez **"Create repository"**

### Ã‰tape 2 : RÃ©cupÃ©rer l'URL du repo

AprÃ¨s crÃ©ation, vous verrez un bouton vert **"Code"**. Cliquez dessus et copiez l'URL HTTPS :
```
https://github.com/jeanmicheldanto-boop/ner-distillation.git
```

### Ã‰tape 3 : Ajouter le remote et pousser

```bash
cd c:\Users\Lenovo\dataner
git remote add origin https://github.com/jeanmicheldanto-boop/ner-distillation.git
git branch -M main
git push -u origin main
```

**Note** : Il vous demandera votre username/password. Utilisez un **Personal Access Token** Ã  la place du password :
1. Allez sur **https://github.com/settings/tokens**
2. Cliquez **"Generate new token"** â†’ **"Generate new token (classic)"**
3. Donnez-lui un nom : `runpod-access`
4. Cochez : `repo`, `admin:repo_hook`
5. GÃ©nÃ©rez et **copiez le token** (ne le perdez pas !)
6. Quand git demande le password, collez ce token

---

## Phase 2 : Configurer l'Instance RunPod (10 minutes)

### Ã‰tape 1 : Se connecter Ã  RunPod

1. Allez sur **https://www.runpod.io**
2. Connectez-vous avec votre compte
3. Allez Ã  **"Pods"** â†’ **"Create New"**

### Ã‰tape 2 : SÃ©lectionner le GPU et le Template

**Templates** :
- Cherchez **"PyTorch"** ou **"CUDA 11.8"**
- SÃ©lectionnez une image rÃ©cente (2024+)

**GPU Selection** :
- **RTX 4090** (24 GB) : ~$0.70/h - BON CHOIX
- **A100 40GB** : ~$1.50/h - EXCELLENT mais 2x plus cher
- **L40S** : ~$0.50/h - OK mais risque VRAM

**Je recommande RTX 4090** pour dÃ©buter.

### Ã‰tape 3 : Configuration du Pod

| Option | Valeur |
|--------|--------|
| GPU Count | 1 |
| Volume | 50 GB (pour datasets + checkpoints) |
| Container Disk | 20 GB |
| Expose HTTP Ports | 8888 (Jupyter, optionnel) |

Cliquez **"Deploy"** et attendez 1-2 minutes.

### Ã‰tape 4 : AccÃ©der Ã  votre Pod

Une fois "Running" :
- Cliquez sur le Pod
- Cliquez **"Connect"** ou **"SSH"**
- Copiez la commande SSH

---

## Phase 3 : Sur RunPod (SSH dans le Pod)

```bash
# Se connecter (remplacer par votre SSH command)
ssh -p YOUR_PORT root@YOUR_IP
```

### Ã‰tape 1 : Cloner le repo

```bash
cd /workspace
git clone https://github.com/jeanmicheldanto-boop/ner-distillation.git
cd ner-distillation
```

### Ã‰tape 2 : Installer les dÃ©pendances

```bash
# Mise Ã  jour systÃ¨me (optionnel mais recommandÃ©)
apt-get update && apt-get upgrade -y

# Installer dÃ©pendances Python
pip install --upgrade pip
pip install -r training_ner/requirements.txt

# VÃ©rifier CUDA
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

**DurÃ©e estimÃ©e** : 5-10 minutes

### Ã‰tape 3 : Uploader vos donnÃ©es

**Option A : Via SCP (direct depuis votre machine)**

```bash
# DEPUIS VOTRE PC (local) :
scp -P YOUR_PORT c:\Users\Lenovo\dataner\corpus\corpus_fr_100k_medico_FINAL.txt root@YOUR_IP:/workspace/ner-distillation/data/
```

**Option B : Via le volume persistant RunPod**

Si vous avez un volume persistant, uploadez via le dashboard RunPod.

### Ã‰tape 4 : PrÃ©parer les donnÃ©es

```bash
cd /workspace/ner-distillation
python training_ner/annotate_corpus.py \
  --input ./data/corpus_fr_100k_medico_FINAL.txt \
  --output ./training_ner/data/ \
  --split 0.8 0.1 0.1 \
  --max_samples 96000 \
  --teacher Jean-Baptiste/camembert-ner

# VÃ©rifier
ls -lah training_ner/data/
```

**DurÃ©e estimÃ©e** : 2-4 heures (l'annotation auto est long)

### Ã‰tape 5 : Valider le setup

```bash
cd training_ner
python validate_setup.py
```

Si tout est âœ… : vous Ãªtes prÃªt !

---

## Phase 4 : Lancer le Training

### Ã‰tape 1 : Distillation

```bash
cd /workspace/ner-distillation/training_ner

# Lancer dans un screen/tmux pour survivre aux dÃ©connexions
screen -S training
python train_kd.py \
  --config configs/kd_camembert.yaml \
  --output artifacts/student_10L

# Pour quitter screen sans l'arrÃªter : Ctrl+A puis D
# Pour se reconnecter : screen -r training
```

**DurÃ©e estimÃ©e** : 4-8 heures (10 epochs)

**Monitoring** :
```bash
# Dans un autre SSH terminal :
tail -f /workspace/ner-distillation/training_ner/artifacts/student_10L/training_log.jsonl
watch -n 10 nvidia-smi  # Voir GPU usage
```

### Ã‰tape 2 : Pruning

```bash
python prune_heads.py \
  --model artifacts/student_10L \
  --rate 0.25 \
  --output artifacts/student_10L_pruned
```

**DurÃ©e estimÃ©e** : 30-60 min

### Ã‰tape 3 : Fine-tuning post-pruning

```bash
python finetune_postprune.py \
  --model artifacts/student_10L_pruned \
  --output artifacts/student_10L_final \
  --epochs 2
```

**DurÃ©e estimÃ©e** : 1-2 heures

---

## Phase 5 : RÃ©cupÃ©rer les RÃ©sultats

### TÃ©lÃ©charger le modÃ¨le final

```bash
# DEPUIS VOTRE PC (local) :
scp -rP YOUR_PORT root@YOUR_IP:/workspace/ner-distillation/training_ner/artifacts/student_10L_final ./my_student_model/
```

### ArrÃªter le Pod

```bash
# Dans le dashboard RunPod
# Cliquez "Terminate" (arrÃªte et facture l'heure en cours)
# ou "Stop" si vous voulez le reprendre
```

---

## ğŸ’° Estimation des CoÃ»ts

| Ã‰tape | DurÃ©e | CoÃ»t (RTX 4090 @$0.70/h) |
|-------|-------|--------------------------|
| Annotation auto | 2-4h | $1.40-2.80 |
| Distillation | 4-8h | $2.80-5.60 |
| Pruning | 0.5-1h | $0.35-0.70 |
| Fine-tuning | 1-2h | $0.70-1.40 |
| **TOTAL** | **7.5-15h** | **$5.25-10.50** |

**TrÃ¨s raisonnable pour un modÃ¨le optimisÃ© !**

---

## âš ï¸ Troubleshooting

### "CUDA out of memory"
```bash
# RÃ©duire batch_size dans configs/kd_camembert.yaml
# batch_size: 16 â†’ 8 ou 4
```

### "Teacher model not found"
```bash
# VÃ©rifier connexion internet sur RunPod
# pip install transformers --upgrade
```

### "DÃ©connexion SSH perdra mon entraÃ®nement"
```bash
# Utilisez screen ou tmux :
screen -S train
python train_kd.py ...
# Ctrl+A, D pour dÃ©tacher
# screen -r train pour revenir
```

### "DonnÃ©es too large"
```bash
# Utiliser le volume persistant RunPod ou rÃ©duire --max_samples
# python annotate_corpus.py ... --max_samples 50000
```

---

## Prochaines Ã©tapes

1. âœ… CrÃ©er repo GitHub et pousser le code
2. âœ… CrÃ©er pod RunPod
3. âœ… Cloner, installer, valider
4. âœ… Uploader corpus
5. âœ… Annoter + Distiller + Pruner
6. âœ… TÃ©lÃ©charger modÃ¨le final
7. âœ… Tester dans votre pipeline production
8. âœ… **Si F1 pipeline >= -1.0 â†’ GO** sinon NO-GO

Besoin d'aide Ã  une Ã©tape ? ğŸš€
